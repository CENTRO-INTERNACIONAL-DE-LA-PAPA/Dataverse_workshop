{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f05G3fJUU0sv"
      },
      "source": [
        "# CIP Dataverse REST API Session\n",
        "\n",
        "Welcome to the CIP REST API course. This Jupyter notebook contains all you need to learn how to retrieve data from Dataverse, including sample code, spece to write your own code and sample answers, which can all be run within the notebook in Python language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAD3zGvMU0sw",
        "outputId": "d942c514-1f1f-40ee-dc7e-fce400db4457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Don't run this code locally (e.g. con VSCode)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFb_n1oLU0sw"
      },
      "source": [
        "# Search API using GET queries via a browser\n",
        "\n",
        "Our first REST call will be searching the CIP dataverse from the **Dataverse Project**\n",
        "\n",
        "We can query the word potato:\n",
        "* https://data.cipotato.org/api/search?q=**The word to search***&key=\"**Paste your API KEY**\"\n",
        "* https://data.cipotato.org/api/search?q=**The word to search***&type=dataverse&key=\"**Paste your API KEY**\"\n",
        "* https://data.cipotato.org/api/search?q=**The word to search***&subtree=\"**Dataverse Identifier**\"&key=\"**Paste your API KEY**\"\n",
        "* https://data.cipotato.org/api/search?q=*&type=dataset&metadata_fields=citation:dsDescription&metadata_fields=citation:author&key=\"**Paste your API KEY**\"\n",
        "* https://data.cipotato.org/api/search?q=potato*&show_relevance=true&show_facets=true&fq=publicationDate:2021&fq=authorName_ss:**\"Gastelo, Manuel\"**&fq=keywordValue_ss:**\"Genomic Selection\"**&key=\"**Paste your API KEY**\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBSOskTVU0sw"
      },
      "source": [
        "### Exercises 1\n",
        "\n",
        "The first set of exercises just use URLs in the browser. You cannot do these within the Python notebook, however we have provided a box where you can note them down. *Don't forget to get you api key before searching*.\n",
        "\n",
        "1. Find a dataverse which you can use to lookop information.\n",
        "2. Create a URL to find information about lateblight.\n",
        "3. Expand your results to include information about a specific author o specific theme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpLkLiY5U0sx"
      },
      "source": [
        "#### Enter you answers here:\n",
        "\n",
        "1.\n",
        "2.\n",
        "3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2amyh0NnU0sx"
      },
      "source": [
        "### Exercises 1 - answers\n",
        "\n",
        "1. https://data.cipotato.org/api/search?q=potato&type=dataverse&key=\"**Paste your API KEY**\"\n",
        "2. https://data.cipotato.org/api/search?q=lateblight*&subtree=potato&key=\"**Paste your API KEY**\"\n",
        "3. https://data.cipotato.org/api/search?q=lateblight*&show_relevance=true&show_facets=true&fq=authorName_ss:%22Hijmans,%20Robert%22&fq=keywordValue_ss:%22Phytophthora%20infestans%22&key=**Paste your API KEY**\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPlOZcZuU0sx"
      },
      "source": [
        "## Search API with Python code\n",
        "\n",
        "To make a request, you'll need to specify the server and extension, using the `requests` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W27_FPTpU0sx"
      },
      "outputs": [],
      "source": [
        "import requests, sys\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "\n",
        "params = {\n",
        "    \"q\": \"*\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "\n",
        "response = requests.get(base_url, params=params, verify=False)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFJ8hSJUU0sx"
      },
      "source": [
        "### Error Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dPO94b_U0sx"
      },
      "outputs": [],
      "source": [
        "import requests, sys\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "\n",
        "params = {\n",
        "    \"q\": \"*\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "\n",
        "response = requests.get(base_url, params=params, verify=False)\n",
        "\n",
        "if response.status_code != 200:\n",
        "    print(f\"Error: {response.raise_for_status()}\")\n",
        "else:\n",
        "    print(f\"{response.ok}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiV7b4UU0sx"
      },
      "source": [
        "### Decoding JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDTK6n0gU0sx"
      },
      "outputs": [],
      "source": [
        "import requests, sys, json\n",
        "from pprint import pprint\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "\n",
        "params = {\n",
        "    \"q\": \"*\",\n",
        "    \"type\":\"dataverse\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "\n",
        "response = requests.get(base_url, params=params, verify=False)\n",
        "\n",
        "print(response.headers)\n",
        "\n",
        "if response.status_code != 200:\n",
        "    print(f\"Error: {response.raise_for_status()}\")\n",
        "else:\n",
        "    print(f\"{response.ok}\")\n",
        "\n",
        "decoded = response.json()\n",
        "\n",
        "pprint(decoded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FNBu6PyU0sx"
      },
      "source": [
        "### Helper Function\n",
        "\n",
        "The helper function allows you to call the request, check the status and decode the json in a single line of code. If you're using lots of REST calls in your script, creating a function will save you a lot of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcSmBVr8U0sx"
      },
      "outputs": [],
      "source": [
        "import requests, sys, json\n",
        "from pprint import pprint\n",
        "\n",
        "def fetch_endpoint(base_url, content_type=\"application/json\",**params):\n",
        "    url = f\"{base_url}\"\n",
        "    headers = {\n",
        "        \"Content-Type\": content_type\n",
        "    }\n",
        "    response = requests.get(url, params=params,headers=headers, verify=False)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.raise_for_status()}\")\n",
        "    else:\n",
        "        print(f\"{response.ok}\")\n",
        "\n",
        "    if content_type == \"application/json\":\n",
        "        return response.json()\n",
        "    else:\n",
        "        return response.text\n",
        "\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "params = {\n",
        "    \"q\": \"*\",\n",
        "    \"type\":\"dataset\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "con = \"application/json\"\n",
        "\n",
        "get_data = fetch_endpoint(base_url, con, **params)\n",
        "\n",
        "pprint(get_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL0540mzU0sy"
      },
      "source": [
        "### Exercises 2\n",
        "\n",
        "1. Write a script to **lookup** for datasets related to native potatoes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSEuI2_rU0sy"
      },
      "outputs": [],
      "source": [
        "#TODO Exercise 2.1\n",
        "\n",
        "import requests, sys, json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF6J68HXU0sy"
      },
      "source": [
        "### Exercises 2 - answers\n",
        "\n",
        "1. Write a script to **lookup** for datasets related to native potatoes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NET5Wje7U0sy"
      },
      "outputs": [],
      "source": [
        "import requests, sys, json\n",
        "from pprint import pprint\n",
        "\n",
        "def fetch_endpoint(base_url, content_type=\"application/json\",**params):\n",
        "    url = f\"{base_url}\"\n",
        "    headers = {\n",
        "        \"Content-Type\": content_type\n",
        "    }\n",
        "    response = requests.get(url, params=params,headers=headers, verify=False)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.raise_for_status()}\")\n",
        "    else:\n",
        "        print(f\"{response.ok}\")\n",
        "\n",
        "    if content_type == \"application/json\":\n",
        "        return response.json()\n",
        "    else:\n",
        "        return response.text\n",
        "\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "params = {\n",
        "    \"q\": \"potatoes*\",\n",
        "    \"type\":\"dataset\",\n",
        "    \"subtree\":\"potato\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "con = \"application/json\"\n",
        "\n",
        "get_data = fetch_endpoint(base_url, con, **params)\n",
        "\n",
        "pprint(get_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUuv68aGU0sy"
      },
      "source": [
        "### Using results: fetching specific data\n",
        "\n",
        "Since JSON is a dictionary, you can pull out a single datapoint using the key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RscjESYaU0sy"
      },
      "outputs": [],
      "source": [
        "print(get_data.keys())\n",
        "print(get_data.get(\"data\",{}).keys())\n",
        "pprint(get_data.get(\"data\",{}).get(\"items\",[]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq8DjE6kU0sy"
      },
      "source": [
        "We can add to our previous script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONsHuqZPU0sy"
      },
      "outputs": [],
      "source": [
        "import requests, sys, json\n",
        "from pprint import pprint\n",
        "\n",
        "def fetch_endpoint(base_url, content_type=\"application/json\",**params):\n",
        "    url = f\"{base_url}\"\n",
        "    headers = {\n",
        "        \"Content-Type\": content_type\n",
        "    }\n",
        "    response = requests.get(url, params=params,headers=headers, verify=False)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.raise_for_status()}\")\n",
        "    else:\n",
        "        print(f\"{response.ok}\")\n",
        "\n",
        "    if content_type == \"application/json\":\n",
        "        return response.json()\n",
        "    else:\n",
        "        return response.text\n",
        "\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "params = {\n",
        "    \"q\": \"potatoes*\",\n",
        "    \"type\":\"dataset\",\n",
        "    \"subtree\":\"potato\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "con = \"application/json\"\n",
        "\n",
        "get_data = fetch_endpoint(base_url, con, **params)\n",
        "\n",
        "items = get_data.get(\"data\",{}).get(\"items\",[])[0]\n",
        "\n",
        "print(items.keys())\n",
        "print(items.get(\"url\"))\n",
        "for i, author in enumerate(items.get(\"authors\")):\n",
        "    print(f\"Author {i+1}: {author}\")\n",
        "pprint(items.get(\"description\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqwkSacsU0sy"
      },
      "source": [
        "### Exercises 3\n",
        "\n",
        "1. Write a script to lookup for a dataset related to roots ans tubers and print the geographic coverage and the global ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QtqnnuWU0sy"
      },
      "outputs": [],
      "source": [
        "##TODO Exercise 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0wWWxNXU0sy"
      },
      "source": [
        "### Excercises 3 - answers\n",
        "\n",
        "1. Write a script to lookup for a dataset related to roots and tubers and print the geographic coverage and the global ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVKlQeFKU0sy"
      },
      "outputs": [],
      "source": [
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "params = {\n",
        "    \"q\": \"*\",\n",
        "    \"type\":\"dataverse\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "con = \"application/json\"\n",
        "\n",
        "get_data = fetch_endpoint(base_url, con, **params)\n",
        "pprint(get_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd-1fcq_U0sy"
      },
      "outputs": [],
      "source": [
        "base_url = \"https://data.cipotato.org/api/search\"\n",
        "params = {\n",
        "    \"q\": \"virus*\",\n",
        "    \"type\":\"dataset\",\n",
        "    \"subtree\":\"rtas\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96'\n",
        "}\n",
        "con = \"application/json\"\n",
        "\n",
        "get_data = fetch_endpoint(base_url, con, **params)\n",
        "\n",
        "items = get_data.get(\"data\",{}).get(\"items\",[])[0]\n",
        "pprint(items)\n",
        "print(items.keys())\n",
        "print(items.get(\"geographicCoverage\"))\n",
        "pprint(items.get(\"global_id\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmQr8iK2U0sy"
      },
      "source": [
        "# Retrieving Data using REST API with GET Requests in Browser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzR6oJCEU0sy"
      },
      "source": [
        "Our second type of REST call will be searching the CIP dataverse from the **Dataverse Project**\n",
        "\n",
        "We can query the word potato:\n",
        "\n",
        "* https://data.cipotato.org/api/access/dataset/:persistentId/?persistentId=**\"Paste DOI identifier\"**\n",
        "* https://data.cipotato.org/api/access/dataset/:persistentId/versions/:latest?persistentId=**\"Paste DOI identifier\"**\n",
        "* https://data.cipotato.org/api/access/datafile/:persistentId?persistentId=**\"doi:10.21223/1RALF3/3HRBMX\"**\n",
        "* For multiple files we're gonna use code!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aF5bpjDU0sy"
      },
      "source": [
        "## Retrieve a single data with REST API using Python code\n",
        "\n",
        "To make a request, you'll need to specify the server and extension, using the `requests` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJsO5YSJU0sy"
      },
      "outputs": [],
      "source": [
        "import requests, sys\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/access/dataset/:persistentId\"\n",
        "\n",
        "params = {\n",
        "    \"persistentId\": \"doi:10.21223/JTYQA6\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96',\n",
        "    \"format\":\"original\",\n",
        "}\n",
        "\n",
        "response = requests.get(base_url, params=params, verify=False)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvgwbcEuU0sy"
      },
      "source": [
        "Now, let's save the content to a variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K-Qfjx3U0sz"
      },
      "outputs": [],
      "source": [
        "content = response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgip8LpeU0sz"
      },
      "source": [
        "It's important to note that excel files are codified as binary and we need to access it by creating a binary object that allow us to make operations like reading ansd seeking as id the data were stored in a file. Then, we can zip it so we can handle the binary data using the `with` keyword."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMyTh1y6U0sz"
      },
      "outputs": [],
      "source": [
        "import zipfile, io\n",
        "\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(content))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4rEoylRU0sz"
      },
      "source": [
        "As says above, treating the binery data as a file object and zip it, we can obtain the file names on the zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9pvu6RGU0sz",
        "outputId": "071a9c96-be8e-4395-e6de-babd589050e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['01_daily_data.xlsx', 'data_dictionary.xlsx']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zip_names = [i for i in zip_file.namelist() if i.endswith(('.xls', '.xlsx', '.csv', '.tab'))]\n",
        "zip_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oezMyjeU0sz"
      },
      "source": [
        "Finally, using the `with` keyword, we can make oprations like rading the binary data as a pandas **dataframe**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdxFHdw4U0sz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "with zip_file.open(zip_names[0]) as file:\n",
        "    df = pd.read_excel(file, sheet_name=None)\n",
        "\n",
        "print(list(df.keys()))\n",
        "\n",
        "df[\"Hoja1\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbejOWymU0sz"
      },
      "source": [
        "All the code above can be translated to a function as we did before! Let's do it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md4ukrwgU0sz"
      },
      "outputs": [],
      "source": [
        "def get_data(base_url, content_type=\"application/json\",**params):\n",
        "\n",
        "    url = f\"{base_url}\"\n",
        "    headers = {\n",
        "        \"Content-Type\": content_type\n",
        "    }\n",
        "    response = requests.get(url, params=params,headers=headers, verify=False)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.raise_for_status()}\")\n",
        "    else:\n",
        "        print(f\"{response.ok}\")\n",
        "\n",
        "    content = response.content\n",
        "    zip_file = zipfile.ZipFile(io.BytesIO(content))\n",
        "    zip_names = [i for i in zip_file.namelist() if i.endswith(('.xls', '.xlsx', '.csv', '.tab'))]\n",
        "    print(zip_names)\n",
        "\n",
        "    return zip_file, zip_names\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/access/dataset/:persistentId\"\n",
        "\n",
        "params = {\n",
        "    \"persistentId\": \"doi:10.21223/M97ZQS\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96',\n",
        "    \"format\":\"original\",\n",
        "}\n",
        "\n",
        "\n",
        "zip_file, zip_names = get_data(base_url, **params)\n",
        "\n",
        "with zip_file.open(zip_names[0]) as file:\n",
        "    df = pd.read_excel(file, sheet_name=None)\n",
        "\n",
        "print(list(df.keys()))\n",
        "\n",
        "df['F1_Selec_Crit']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises 4\n",
        "\n",
        "1. Write a script to download and load a file from a dataset."
      ],
      "metadata": {
        "id": "XhHzEGokWI5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO Exercise 4.1\n"
      ],
      "metadata": {
        "id": "K_iaIIS3W80R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercisas 4 - answers\n",
        "\n",
        "1. Write a script to download and load a file from a dataset."
      ],
      "metadata": {
        "id": "TXKUsYMhXBOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, sys\n",
        "import zipfile, io\n",
        "import pandas as pd\n",
        "\n",
        "def get_data(base_url, content_type=\"application/json\",**params):\n",
        "\n",
        "    url = f\"{base_url}\"\n",
        "    headers = {\n",
        "        \"Content-Type\": content_type\n",
        "    }\n",
        "    response = requests.get(url, params=params,headers=headers, verify=False)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.raise_for_status()}\")\n",
        "    else:\n",
        "        print(f\"{response.ok}\")\n",
        "\n",
        "    content = response.content\n",
        "    zip_file = zipfile.ZipFile(io.BytesIO(content))\n",
        "    zip_names = [i for i in zip_file.namelist() if i.endswith(('.xls', '.xlsx', '.csv', '.tab'))]\n",
        "    print(zip_names)\n",
        "\n",
        "    return zip_file, zip_names\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/access/dataset/:persistentId\"\n",
        "\n",
        "params = {\n",
        "    \"persistentId\": \"doi:10.21223/57YIIP\",\n",
        "    'key': '36c4e5ea-7cc3-4e15-b55d-548db5af1b96',\n",
        "    \"format\":\"original\",\n",
        "}\n",
        "\n",
        "\n",
        "zip_file, zip_names = get_data(base_url, **params)\n",
        "\n",
        "with zip_file.open(\"01_data_yield_Mugurero_2005.xlsx\") as file:\n",
        "    df = pd.read_excel(file, sheet_name=None)\n",
        "\n",
        "print(list(df.keys()))\n",
        "\n",
        "df[\"Sheet1\"]\n"
      ],
      "metadata": {
        "id": "f0OnXJkOXOeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkvItMU1U0sz"
      },
      "source": [
        "## Retrieve multiple data with REST API using Python code\n",
        "\n",
        "On native api section of the API we have a section where we can list all the files in a Dataset. This is useful to get the **FILE ID** of each file.\n",
        "\n",
        "Here is an example on the browser: https://data.cipotato.org/api/datasets/:persistentId/versions/:latest/files?persistentId=doi:10.21223/M97ZQS\n",
        "\n",
        "```\n",
        "{\n",
        "  \"status\": \"OK\",\n",
        "  \"data\": [\n",
        "    {\n",
        "      \"label\": \"01_data_F1_Select_crit.tab\",\n",
        "      \"restricted\": false,\n",
        "      \"version\": 4,\n",
        "      \"datasetVersionId\": 2569,\n",
        "      \"categories\": [\n",
        "        \"Data\"\n",
        "      ],\n",
        "      \"dataFile\": {\n",
        "        \"id\": 10487,\n",
        "        \"persistentId\": \"doi:10.21223/M97ZQS/6OXAOK\",\n",
        "        \"pidURL\": \"https://doi.org/10.21223/M97ZQS/6OXAOK\",\n",
        "        \"filename\": \"01_data_F1_Select_crit.tab\",\n",
        "        \"contentType\": \"text/tab-separated-values\",\n",
        "        \"filesize\": 1090,\n",
        "        \"storageIdentifier\": \"file://1939d6fb517-a096d1186bf8\",\n",
        "        \"originalFileFormat\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n",
        "        \"originalFormatLabel\": \"MS Excel Spreadsheet\",\n",
        "        \"originalFileSize\": 29370,\n",
        "        \"originalFileName\": \"01_data_F1_Select_crit.xlsx\",\n",
        "        \"UNF\": \"UNF:6:Pz1aSr645YjmE0Bp8UdepQ==\",\n",
        "        \"rootDataFileId\": -1,\n",
        "        \"md5\": \"c1e610f01e13d2e9f424c9b903223c32\",\n",
        "        \"checksum\": {\n",
        "          \"type\": \"MD5\",\n",
        "          \"value\": \"c1e610f01e13d2e9f424c9b903223c32\"\n",
        "        },\n",
        "        \"creationDate\": \"2024-12-06\"\n",
        "      }\n",
        "    }]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSJBSoSwU0sz"
      },
      "source": [
        "In this case of retrieving multiple data files, we can get the unique file ID within a dataset and load all these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFNAb_V7U0sz"
      },
      "outputs": [],
      "source": [
        "import requests, sys\n",
        "import zipfile, io\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/datasets/:persistentId/versions/:latest/files?persistentId=\"\n",
        "doi = \"doi:10.21223/M97ZQS\"\n",
        "dataset_url = base_url + doi\n",
        "response = requests.get(dataset_url, verify=False).json()\n",
        "files_ids = [str(file[\"dataFile\"][\"id\"]) for file in response[\"data\"]]\n",
        "pprint(files_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW92yKw1U0s0"
      },
      "source": [
        "Note that as in the section of searching, we used specific datapoints of the dictionary (JSON) to retrieve the ID within the dataFIle section. Now with the file ID's, we can get specific files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_j7BnI_U0s0"
      },
      "outputs": [],
      "source": [
        "base_url = \"https://data.cipotato.org/api/access/datafiles/\"\n",
        "file_ids = \",\".join(files_ids)  # Create a comma-separated list of file IDs\n",
        "dataurl = base_url + file_ids + \"?format=original\"\n",
        "response = requests.get(dataurl, verify=False)\n",
        "if response.status_code == 200:\n",
        "    content = response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9qJEh_zU0s0"
      },
      "source": [
        "As before, once we have the binary data we can see the file names and load specific files as dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj4L45fbU0s0"
      },
      "outputs": [],
      "source": [
        "zip_file = zipfile.ZipFile(io.BytesIO(content))\n",
        "zip_names = [i for i in zip_file.namelist() if i.endswith(('.xls', '.xlsx', '.csv', '.tab'))]\n",
        "pprint(zip_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu8WRe3lU0s0",
        "outputId": "dbd12a9e-334f-4b4a-cb0f-24d48b72d727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['F4_ Harvest_Mother']\n"
          ]
        }
      ],
      "source": [
        "with zip_file.open(zip_names[4]) as file:\n",
        "    df = pd.read_excel(file, sheet_name=None)\n",
        "\n",
        "print(list(df.keys()))\n",
        "\n",
        "df = df['F4_ Harvest_Mother'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcnKrgr2U0s0"
      },
      "source": [
        "Again, we can make a function if we want to use it multiple times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XKFZgZZCU0s0"
      },
      "outputs": [],
      "source": [
        "# First the helper function\n",
        "\n",
        "def get_file_ids(base_url, doi):\n",
        "    dataset_url = base_url + doi\n",
        "    response = requests.get(dataset_url, verify=False).json()\n",
        "    files_ids = [str(file[\"dataFile\"][\"id\"]) for file in response[\"data\"]]\n",
        "    return files_ids\n",
        "\n",
        "# Now the main function\n",
        "\n",
        "def get_data(base_url, file_ids):\n",
        "    base_url = \"https://data.cipotato.org/api/access/datafiles/\"\n",
        "    file_ids = \",\".join(file_ids)  # Create a comma-separated list of file IDs\n",
        "    dataurl = base_url + file_ids + \"?format=original\"\n",
        "    response = requests.get(dataurl, verify=False)\n",
        "    if response.status_code == 200:\n",
        "        content = response.content\n",
        "        zip_file = zipfile.ZipFile(io.BytesIO(content))\n",
        "        zip_names = [i for i in zip_file.namelist() if i.endswith(('.xls', '.xlsx', '.csv', '.tab'))]\n",
        "    return zip_file, zip_names\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case we can loop the function `get_file_ids` across multiple datasets and select a expecific excel file to load as a dataframe with pandas."
      ],
      "metadata": {
        "id": "rdOqW1DFYf66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZKFWmMhU0s0"
      },
      "outputs": [],
      "source": [
        "base_url = \"https://data.cipotato.org/api/datasets/:persistentId/versions/:latest/files?persistentId=\"\n",
        "dois = [\"doi:10.21223/M97ZQS\", \"doi:10.21223/57YIIP\", \"doi:10.21223/3UT8HI\"]\n",
        "\n",
        "files_ids = []\n",
        "\n",
        "for doi in dois:\n",
        "    ids = get_file_ids(base_url, doi)\n",
        "    files_ids.extend(ids)\n",
        "\n",
        "pprint(files_ids)\n",
        "\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/access/datafiles/\"\n",
        "zip_file, zip_names = get_data(base_url, files_ids)\n",
        "pprint(zip_names)\n",
        "\n",
        "with zip_file.open(zip_names[11]) as file:\n",
        "    df = pd.read_excel(file, sheet_name=None)\n",
        "\n",
        "print(list(df.keys()))\n",
        "\n",
        "df = df['F4_ Harvest_Mother'].copy()\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-twCvWfTU0s0"
      },
      "source": [
        "Finally, we can make a plot!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdIr70eAU0s0"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the standard error\n",
        "df['SE'] = df.groupby('INSTN')['TTYNA'].transform(lambda x: x.std() / (len(x) ** 0.5))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df, x='PLOT', y='TTYNA', hue='INSTN', style='INSTN', s=100, palette='deep', legend='full')\n",
        "plt.errorbar(df['PLOT'], df['TTYNA'], yerr=df['SE'], fmt='none', c='gray', capsize=3)\n",
        "\n",
        "plt.title('TTYNA by PLOT with Standard Error')\n",
        "plt.xlabel('PLOT')\n",
        "plt.ylabel('TTYNA')\n",
        "plt.legend(title='INSTN')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises 5\n",
        "\n",
        "1. Write a script to load multiple files from at least 3 different experiments.\n"
      ],
      "metadata": {
        "id": "a15N2MqFX2gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO Exercise 5.1"
      ],
      "metadata": {
        "id": "L_D06ueGarnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Excercises 5 - answers\n",
        "\n",
        "1. Write a script to load multiple files from at least 3 different experiments."
      ],
      "metadata": {
        "id": "zBczTKPQatQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://data.cipotato.org/api/datasets/:persistentId/versions/:latest/files?persistentId=\"\n",
        "dois = [\"doi:10.21223/RHSVIY\", \"doi:10.21223/7WC7FM\", \"doi:10.21223/GCJRH6\"] # Gastelo experiments\n",
        "\n",
        "files_ids = []\n",
        "\n",
        "for doi in dois:\n",
        "    ids = get_file_ids(base_url, doi)\n",
        "    files_ids.extend(ids)\n",
        "\n",
        "pprint(files_ids)\n",
        "\n",
        "\n",
        "base_url = \"https://data.cipotato.org/api/access/datafiles/\"\n",
        "zip_file, zip_names = get_data(base_url, files_ids)\n",
        "pprint(zip_names)\n",
        "\n",
        "with zip_file.open(zip_names[3]) as file:\n",
        "    df = pd.read_excel(file, sheet_name=None)\n",
        "\n",
        "print(list(df.keys()))\n",
        "\n",
        "df = df['Fieldbook'].copy()\n",
        "df\n"
      ],
      "metadata": {
        "id": "tfqR7AwHa21h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "piero",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yF6J68HXU0sy",
        "C0wWWxNXU0sy",
        "TXKUsYMhXBOt",
        "zBczTKPQatQ2"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}